{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e357422-068c-4fef-9ce7-e14bbc2c2408",
   "metadata": {},
   "source": [
    "Q2: List down techniques used to handle missing data. Give an example of each with python code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829ee8f1-6069-4e7b-8770-a23d4bff3953",
   "metadata": {},
   "source": [
    "Dropping Missing Values:\n",
    "This involves removing rows or columns with missing data.\n",
    "python\n",
    "Copy code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa58e021-05a4-48fc-a932-57bcdcb55831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "     A    B\n",
      "0  1.0  NaN\n",
      "1  2.0  2.0\n",
      "2  NaN  3.0\n",
      "3  4.0  4.0\n",
      "4  5.0  NaN\n",
      "\n",
      "DataFrame after dropping rows with missing values:\n",
      "     A    B\n",
      "1  2.0  2.0\n",
      "3  4.0  4.0\n",
      "\n",
      "DataFrame after dropping columns with missing values:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame with missing values\n",
    "data = {'A': [1, 2, None, 4, 5],\n",
    "        'B': [None, 2, 3, 4, None]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Drop rows with any missing values\n",
    "df_dropped_rows = df.dropna()\n",
    "\n",
    "# Drop columns with any missing values\n",
    "df_dropped_columns = df.dropna(axis=1)\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nDataFrame after dropping rows with missing values:\")\n",
    "print(df_dropped_rows)\n",
    "print(\"\\nDataFrame after dropping columns with missing values:\")\n",
    "print(df_dropped_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0287d72d-a08f-4add-8d84-de587cd5410a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb617189-a0ec-41c1-b7b8-b365805cd69d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbaf4ef3-37b5-4658-b9ed-4052ac74ce58",
   "metadata": {},
   "source": [
    "Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2b24ba-f6e6-4c85-9943-d807a9a39cdf",
   "metadata": {},
   "source": [
    "Imbalanced data refers to a situation in which the classes or categories within a dataset are not represented equally. One class (the minority class) has significantly fewer instances compared to another class (the majority class). Imbalanced data is a common issue in various domains, including fraud detection, medical diagnosis, and rare event prediction.\n",
    "\n",
    "For example, let's consider a binary classification problem to predict whether an online transaction is fraudulent or not. In a real-world scenario, fraudulent transactions are relatively rare compared to legitimate transactions. This can lead to imbalanced data, where the majority of transactions are legitimate (majority class), and only a small portion are fraudulent (minority class).\n",
    "\n",
    "If imbalanced data is not handled appropriately, several challenges and issues can arise:\n",
    "\n",
    "Biased Model Performance: Machine learning models trained on imbalanced data tend to perform poorly on the minority class. The model may become biased towards the majority class due to its prevalence, leading to lower accuracy and predictive power for the minority class.\n",
    "\n",
    "Misclassification of Minority Class: Since the model is biased towards the majority class, it may struggle to correctly identify instances of the minority class. As a result, the model may have a high false negative rate, which can be critical in applications like medical diagnoses or fraud detection.\n",
    "\n",
    "Poor Generalization: Imbalanced data can lead to overfitting, where the model learns the characteristics of the majority class well but fails to generalize to new, unseen data. This is because the model may not have enough representative examples of the minority class to learn its underlying patterns.\n",
    "\n",
    "Loss of Information: Ignoring the minority class can lead to a loss of valuable information. The insights gained from analyzing the minority class may be crucial for making informed decisions in various domains.\n",
    "\n",
    "Uneven Cost Considerations: In some applications, the cost of misclassifying instances from different classes may vary. Misclassifying instances of the minority class could have much larger financial or social implications compared to the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e35424-90af-4ad6-8ce1-ece9bf41d902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6078c08-0ecb-4cec-be47-4368727954eb",
   "metadata": {},
   "source": [
    "Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down-\n",
    "sampling are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "414e5f23-21b8-4f14-9027-20cf94d70713",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1543300697.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    pip install imbalanced-learn\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install imbalanced-learn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomOverSampler\n",
    "\n",
    "X,y = make_classification(n_samples=1000,n_features=10,weights=[0.95,0.05], random_state=42)\n",
    "\n",
    "X_train,X_test, y_train , y_test = train_test_split(X,y,test_size=0.32, random_state=42)\n",
    "\n",
    "over_sampler = RandomOverSample(random_state=42)\n",
    "X_train_upsampled, y_train_upsampled = over_sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "x_train_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6d7d19-b603-41a7-89d4-b880e899a54b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7616f2ed-10c7-4fd9-913d-c7220e43cd69",
   "metadata": {},
   "source": [
    "Q5: What is data Augmentation? Explain SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800e705c-03f3-4332-9c82-178643ad2278",
   "metadata": {},
   "source": [
    "Data augmentation is a technique used to artificially increase the size of a dataset by creating slightly modified or transformed versions of existing data samples. It is commonly employed in machine learning, especially in computer vision tasks, to enhance the model's ability to generalize and improve its performance. By introducing variations to the original data, data augmentation helps the model become more robust to different conditions, orientations, lighting, and other factors that may be encountered during inference.\n",
    "\n",
    "For example, in image classification, data augmentation techniques might involve rotating, flipping, cropping, zooming, or adding noise to images, thereby generating new training examples that capture different variations of the same underlying concept.\n",
    "\n",
    "SMOTE (Synthetic Minority Over-sampling Technique):\n",
    "SMOTE is a popular data augmentation technique specifically designed to address the issue of class imbalance. It generates synthetic samples for the minority class by interpolating between existing instances. This helps to balance the class distribution and provides the model with more representative examples of the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fd7aa3-756f-47da-ab58-5740802a85ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a485460d-d9cf-442d-af83-c3420b7292d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "184d85c7-410c-4433-9027-c5aafb21513d",
   "metadata": {},
   "source": [
    "Q6: What are outliers in a dataset? Why is it essential to handle outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d1ed13-565d-4b7d-aff3-86eb47073c68",
   "metadata": {},
   "source": [
    "Outliers are data points that significantly differ from the rest of the observations in a dataset. They are values that lie far away from the other data points and can potentially distort the overall distribution and statistical analysis of the data. Outliers can arise due to various reasons, such as measurement errors, data entry mistakes, or genuine rare occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e906b2-a3e3-4600-84d5-ce77f59d3ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89670abb-69cb-4548-a07d-cbb056c2f335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2acac2bf-3c9b-4aec-b5b6-c0eb9a300328",
   "metadata": {},
   "source": [
    "Q7: You are working on a project that requires analyzing customer data. However, you notice that some of\n",
    "the data is missing. What are some techniques you can use to handle the missing data in your analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bbd32b-10e1-4620-b5e0-be4c13319f54",
   "metadata": {},
   "source": [
    "When dealing with missing data in a customer data analysis project, several techniques can be employed to handle the missing values appropriately. The choice of technique depends on the nature of the data, the extent of missingness, and the goals of the analysis. Here are some techniques you can consider:\n",
    "\n",
    "Dropping Missing Values:\n",
    "If the missing data is limited and doesn't significantly impact the analysis, you might choose to simply drop the rows or columns with missing values. However, be cautious when using this approach, as it may lead to a loss of valuable information.\n",
    "\n",
    "Mean/Median/Mode Imputation:\n",
    "Fill missing values with the mean (for numerical data), median (robust to outliers), or mode (for categorical data) of the non-missing values in the same column. This approach is suitable when the missingness is random and not substantial.\n",
    "\n",
    "Interpolation:\n",
    "If the data has a time series or sequential nature, you can use interpolation techniques (linear, cubic, etc.) to estimate missing values based on neighboring data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9abdfc3-1d9f-41c7-a995-20d2d714dbf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761adbc7-4b25-46bf-a5b3-a1e5a9c2dd85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ae0faa7-095f-41e3-9239-368b59d59d4a",
   "metadata": {},
   "source": [
    "Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are\n",
    "some strategies you can use to determine if the missing data is missing at random or if there is a pattern\n",
    "to the missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78cd9bb-a22c-4c4c-b244-ee445c064d20",
   "metadata": {},
   "source": [
    "\n",
    "When dealing with missing data in a large dataset, it's important to assess whether the missing data is missing at random (MAR), missing completely at random (MCAR), or missing not at random (MNAR). Determining the nature of the missingness can help you make informed decisions about how to handle the missing data and mitigate potential biases. Here are some strategies to investigate the patterns of missing data:\n",
    "\n",
    "Exploratory Data Analysis (EDA):\n",
    "Begin by conducting thorough exploratory data analysis to visualize the distribution of missing values. Create summary statistics, histograms, and heatmaps to identify which variables have missing values and the extent of the missingness. This initial assessment can provide insights into the missing data patterns.\n",
    "\n",
    "Missingness Heatmap:\n",
    "Create a heatmap that shows the correlations between missing values in different variables. This can help you identify if there is a specific pattern of missingness across variables.\n",
    "\n",
    "Pattern Visualization:\n",
    "Plot the available data against variables with missing values. This can help you visually inspect whether the missing data has a specific pattern related to other variables. For example, you can use scatter plots or box plots to compare the distribution of missing and non-missing values across different variables.\n",
    "\n",
    "Missingness by Category:\n",
    "Analyze if the missing data is related to specific categories within a categorical variable. You can create bar plots or contingency tables to observe if certain categories have a higher rate of missingness.\n",
    "\n",
    "Statistical Tests:\n",
    "Perform statistical tests to assess if there is a significant difference between groups with missing values and groups without missing values. For example, use t-tests or chi-squared tests to compare means or proportions between these groups.\n",
    "\n",
    "Correlation Analysis:\n",
    "Examine the correlation between missingness and other variables. If certain variables are highly correlated with missing values, it might suggest a pattern of non-random missingness.\n",
    "\n",
    "Domain Knowledge:\n",
    "Leverage your domain expertise to understand if the missing data patterns align with what you know about the data generating process. Sometimes, missingness can be explained by external factors that you are aware of.\n",
    "\n",
    "Data Collection Process:\n",
    "Investigate the data collection process to determine if there were any systematic issues or biases that could have led to the missing data. This might involve understanding how the data was collected, recorded, or entered.\n",
    "\n",
    "Time-Dependent Analysis:\n",
    "If your data is time-dependent, examine if the missingness varies over time. This can provide insights into potential patterns or changing data collection practices.\n",
    "\n",
    "Machine Learning Models:\n",
    "Train machine learning models to predict the missing values based on other variables. If the model performs well, it suggests that there might be a pattern to the missing data that can be captured using the available features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fa9334-3884-4efc-9bd6-4aef7ff04c95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c3286f4-a401-4416-8238-0127b7825f36",
   "metadata": {},
   "source": [
    "Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the\n",
    "dataset do not have the condition of interest, while a small percentage do. What are some strategies you\n",
    "can use to evaluate the performance of your machine learning model on this imbalanced dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3a8d46-646d-4e42-85ce-d3b8721789d1",
   "metadata": {},
   "source": [
    "Confusion Matrix Analysis:\n",
    "Analyze the confusion matrix to gain insights into how the model is performing. Pay attention to false positives and false negatives, as their implications can be critical in medical diagnosis.\n",
    "\n",
    "Threshold Adjustment:\n",
    "Experiment with different probability thresholds to balance precision and recall according to your specific needs. Depending on the medical context, you might prioritize one metric over the other.\n",
    "\n",
    "Stratified Sampling:\n",
    "When splitting your dataset into training and testing sets, use stratified sampling to ensure that both classes are represented proportionally in both sets.\n",
    "\n",
    "Cross-Validation:\n",
    "Utilize techniques like stratified k-fold cross-validation to ensure that the model's performance is consistent across different folds of the data.\n",
    "\n",
    "Resampling Techniques:\n",
    "Apply techniques like oversampling the minority class (e.g., Synthetic Minority Over-sampling Technique or SMOTE) to balance class distribution in training sets and test the model on balanced data.\n",
    "\n",
    "Ensemble Methods:\n",
    "Consider using ensemble methods like Random Forest or Gradient Boosting, which can handle imbalanced data more effectively by aggregating predictions from multiple models.\n",
    "\n",
    "Cost-Sensitive Learning:\n",
    "Assign different misclassification costs to the classes, reflecting the real-world impact of false positives and false negatives in medical diagnosis.\n",
    "\n",
    "Feature Engineering:\n",
    "Develop informative features that help the model differentiate between the classes. Consult domain experts to identify relevant features.\n",
    "\n",
    "Domain Expertise:\n",
    "Collaborate with medical professionals to interpret and validate the model's results, ensuring that they align with clinical insights.\n",
    "\n",
    "Improve Data Collection:\n",
    "Collect more data, especially for the minority class, to enhance the model's ability to learn from diverse examples.\n",
    "\n",
    "Robustness Testing:\n",
    "Test the model's performance on external datasets or real-world scenarios to ensure its generalization capabilities.\n",
    "\n",
    "By combining these strategies and customizing your approach to the specific medical diagnosis problem, you can effectively evaluate the performance of your machine learning model on an imbalanced dataset and make informed decisions about its deployment in a clinical setting.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0cda4b-aa8f-4c2a-a1f7-8a8bcbba152c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "419ce17d-e7c7-4d5a-8ca4-f3a5ba891152",
   "metadata": {},
   "source": [
    "Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is\n",
    "unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to\n",
    "balance the dataset and down-sample the majority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad11d7a-106d-48d7-a332-1a80074e0271",
   "metadata": {},
   "source": [
    "Random Under-sampling:\n",
    "Randomly select a subset of instances from the majority class to match the size of the minority class. This approach can help balance the class distribution but may lead to loss of information.\n",
    "\n",
    "Cluster-Based Under-sampling:\n",
    "Use clustering techniques to group similar instances from the majority class and then select representatives from each cluster to down-sample.\n",
    "\n",
    "Tomek Links:\n",
    "Identify pairs of instances (one from the majority class and one from the minority class) that are close to each other and remove the majority class instance, thus emphasizing the decision boundary.\n",
    "\n",
    "Edited Nearest Neighbors (ENN):\n",
    "Remove instances from the majority class that are misclassified by their k-nearest neighbors from both classes, effectively trimming noisy instances.\n",
    "\n",
    "Neighborhood Cleaning Rule (NCR):\n",
    "Combine ENN with the k-nearest neighbors rule, removing instances that are misclassified by their neighbors.\n",
    "\n",
    "NearMiss:\n",
    "Select instances from the majority class that are closest to the minority class instances, ensuring a more balanced representation.\n",
    "\n",
    "Balanced Random Forest (BRF):\n",
    "Use ensemble methods like Balanced Random Forest that down-sample the majority class during the construction of decision trees.\n",
    "\n",
    "Down-sampling with Imbalanced-Learn:\n",
    "Utilize the RandomUnderSampler class from the imbalanced-learn library to perform random under-sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f97a40-cfd4-4dc2-9479-e5c89f61d0da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
